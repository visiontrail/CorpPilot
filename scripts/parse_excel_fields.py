#!/usr/bin/env python3
"""
Excel å­—æ®µè§£æè„šæœ¬

ç”¨äºè§£æ Excel æ–‡ä»¶ä¸­çš„æ‰€æœ‰ Sheet å’Œå­—æ®µä¿¡æ¯ï¼Œè¾“å‡ºç»“æ„åŒ–çš„æ•°æ®å­—å…¸ã€‚
"""

import pandas as pd
import json
from pathlib import Path
from typing import Dict, List, Any
import sys


def parse_excel_file(file_path: str) -> Dict[str, Any]:
    """
    è§£æ Excel æ–‡ä»¶ï¼Œæå–æ‰€æœ‰ Sheet çš„å­—æ®µä¿¡æ¯

    Args:
        file_path: Excel æ–‡ä»¶è·¯å¾„

    Returns:
        åŒ…å«æ‰€æœ‰ Sheet å­—æ®µä¿¡æ¯çš„å­—å…¸
    """
    file_path = Path(file_path)

    if not file_path.exists():
        raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")

    # è·å–æ‰€æœ‰ Sheet åç§°
    xl = pd.ExcelFile(file_path)
    sheet_names = xl.sheet_names

    result = {
        "file_name": file_path.name,
        "file_path": str(file_path),
        "total_sheets": len(sheet_names),
        "sheets": {}
    }

    for sheet_name in sheet_names:
        # è¯»å– Sheet
        df = pd.read_excel(file_path, sheet_name=sheet_name)

        # è·å–å­—æ®µä¿¡æ¯
        columns = list(df.columns)
        row_count = len(df)

        # è·å–æ¯åˆ—çš„æ•°æ®ç±»å‹å’Œç¤ºä¾‹å€¼
        column_info = {}
        for col in columns:
            col_data = df[col]
            dtype = str(col_data.dtype)

            # è·å–éç©ºæ ·æœ¬å€¼ï¼ˆæœ€å¤š3ä¸ªï¼‰
            non_null_values = col_data.dropna().head(3).tolist()
            sample_values = [str(v) for v in non_null_values]

            # ç»Ÿè®¡ç©ºå€¼æ•°é‡
            null_count = col_data.isna().sum()
            null_percentage = (null_count / row_count) * 100 if row_count > 0 else 0

            # å¯¹äºå”¯ä¸€å€¼è¾ƒå°‘çš„å­—æ®µï¼Œè·å–æ‰€æœ‰å”¯ä¸€å€¼
            unique_count = col_data.nunique()
            unique_values = []
            if unique_count <= 20 and unique_count > 0:
                unique_values = [str(v) for v in col_data.dropna().unique()]

            column_info[col] = {
                "data_type": dtype,
                "sample_values": sample_values,
                "null_count": int(null_count),
                "null_percentage": round(null_percentage, 2),
                "unique_count": int(unique_count),
                "unique_values": unique_values if unique_values else None
            }

        result["sheets"][sheet_name] = {
            "column_count": len(columns),
            "row_count": row_count,
            "columns": columns,
            "column_details": column_info
        }

    return result


def print_markdown_dictionary(data: Dict[str, Any]):
    """
    å°†è§£æç»“æœä»¥ Markdown æ ¼å¼è¾“å‡º

    Args:
        data: è§£æç»“æœæ•°æ®
    """
    print(f"\n# ğŸ“‹ æ•°æ®å­—å…¸ - {data['file_name']}\n")
    print(f"**æ–‡ä»¶è·¯å¾„**: `{data['file_path']}`  \n")
    print(f"**Sheet æ•°é‡**: {data['total_sheets']}\n")

    for sheet_name, sheet_info in data["sheets"].items():
        print(f"## {sheet_name}\n")
        print(f"- **è¡Œæ•°**: {sheet_info['row_count']:,}")
        print(f"- **åˆ—æ•°**: {sheet_info['column_count']}\n")

        print("| å­—æ®µå | æ•°æ®ç±»å‹ | ç¤ºä¾‹å€¼ | å”¯ä¸€å€¼æ•° | ç©ºå€¼ç‡ | å¤‡æ³¨ |")
        print("|--------|----------|--------|----------|--------|------|")

        for col, details in sheet_info["column_details"].items():
            # æ ¼å¼åŒ–ç¤ºä¾‹å€¼
            samples = ", ".join([f"`{v}`" for v in details["sample_values"]])
            if len(samples) > 50:
                samples = samples[:50] + "..."

            # æ•°æ®ç±»å‹æ˜ å°„
            dtype_map = {
                "object": "string",
                "int64": "integer",
                "float64": "float",
                "datetime64[ns]": "datetime",
                "bool": "boolean"
            }
            dtype = dtype_map.get(details["data_type"], details["data_type"])

            # å”¯ä¸€å€¼æ˜¾ç¤º
            unique_count = details["unique_count"]
            unique_display = unique_count
            if details["unique_values"]:
                unique_str = ", ".join([f"`{v}`" for v in details["unique_values"]])
                if len(unique_str) <= 30:
                    unique_display = f"{unique_count} ({unique_str})"
                else:
                    unique_display = f"{unique_count}"

            # ç©ºå€¼ç‡æ˜¾ç¤º
            null_pct = details["null_percentage"]
            null_display = f"{null_pct:.1f}%"

            print(f"| `{col}` | {dtype} | {samples} | {unique_display} | {null_display} | |")

        print()


def save_json_result(data: Dict[str, Any], output_path: str = None):
    """
    å°†è§£æç»“æœä¿å­˜ä¸º JSON æ–‡ä»¶

    Args:
        data: è§£æç»“æœæ•°æ®
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸ºå½“å‰ç›®å½•ä¸‹çš„ excel_fields.json
    """
    if output_path is None:
        output_path = "excel_fields.json"

    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ“ JSON ç»“æœå·²ä¿å­˜åˆ°: {output_path}")


def main():
    """ä¸»å‡½æ•°"""
    # é»˜è®¤æ–‡ä»¶è·¯å¾„
    default_file = "/Users/guoliang/Desktop/workspace/code/GalaxySpace/GalaxySpaceAI/CostMatrix/testdata/8æœˆä»½è€ƒå‹¤æ•°æ®ç»Ÿè®¡ä¸åˆ†æ1.xlsx"

    # æ”¯æŒå‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        file_path = sys.argv[1]
    else:
        file_path = default_file

    print(f"ğŸ” æ­£åœ¨è§£æ Excel æ–‡ä»¶: {file_path}")

    try:
        data = parse_excel_file(file_path)

        # æ‰“å° Markdown æ ¼å¼çš„æ•°æ®å­—å…¸
        print_markdown_dictionary(data)

        # ä¿å­˜ JSON ç»“æœ
        save_json_result(data)

        print("âœ… è§£æå®Œæˆï¼")

    except FileNotFoundError as e:
        print(f"âŒ é”™è¯¯: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ è§£æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
